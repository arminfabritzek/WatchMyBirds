"""
Threading/Queue Stress Test for DetectionManager.

Purpose: Verify DetectionManager's threading and queue mechanisms are stable under stress.

Tests verify:
- Threads start and stop within defined timeouts
- Queue does not exceed max size (backpressure)
- No deadlocks under high load
- No exceptions during operation
- DetectionManager.stop() reliably terminates all threads

Strategy:
- Fake capture with high frame rate
- Mock Detection/Classify/Persistence (fast, in-memory)
- Simulate backpressure with artificial delays
- Verify clean shutdown
"""

import queue
import threading
import time
from dataclasses import dataclass

import numpy as np


@dataclass
class MockFrame:
    """Lightweight mock frame for stress testing."""

    data: np.ndarray
    timestamp: float
    frame_id: int


class HighRateVideoCapture:
    """
    Mock video capture that generates frames as fast as possible.

    Used to stress test the pipeline's ability to handle high frame rates.
    """

    def __init__(self, max_frames: int = 1000):
        self._frame_count = 0
        self._max_frames = max_frames
        self._is_opened = True
        # Minimal 100x100 frame for speed
        self._frame_template = np.zeros((100, 100, 3), dtype=np.uint8)

    def isOpened(self):
        return self._is_opened and self._frame_count < self._max_frames

    def read(self):
        if not self.isOpened():
            return False, None

        self._frame_count += 1
        # Create unique frame by modifying first pixel
        frame = self._frame_template.copy()
        frame[0, 0, 0] = self._frame_count % 256
        return True, frame

    def release(self):
        self._is_opened = False

    def get_frame_count(self):
        return self._frame_count


class StressTestQueue:
    """
    Thread-safe queue with monitoring for stress testing.

    Tracks max size reached, total items processed, and overflow attempts.
    """

    def __init__(self, maxsize: int = 10):
        self._queue = queue.Queue(maxsize=maxsize)
        self._maxsize = maxsize
        self._total_put = 0
        self._total_get = 0
        self._max_size_reached = 0
        self._overflow_count = 0
        self._lock = threading.Lock()

    def put(self, item, block: bool = True, timeout: float | None = None):
        """Put with overflow tracking."""
        try:
            self._queue.put(item, block=block, timeout=timeout)
            with self._lock:
                self._total_put += 1
                current_size = self._queue.qsize()
                if current_size > self._max_size_reached:
                    self._max_size_reached = current_size
        except queue.Full:
            with self._lock:
                self._overflow_count += 1
            raise

    def put_nowait(self, item):
        """Non-blocking put with overflow tracking."""
        try:
            self._queue.put_nowait(item)
            with self._lock:
                self._total_put += 1
        except queue.Full:
            with self._lock:
                self._overflow_count += 1
            raise

    def get(self, block: bool = True, timeout: float | None = None):
        """Get with tracking."""
        item = self._queue.get(block=block, timeout=timeout)
        with self._lock:
            self._total_get += 1
        return item

    def get_nowait(self):
        """Non-blocking get with tracking."""
        item = self._queue.get_nowait()
        with self._lock:
            self._total_get += 1
        return item

    def qsize(self):
        return self._queue.qsize()

    def empty(self):
        return self._queue.empty()

    def full(self):
        return self._queue.full()

    def get_stats(self) -> dict:
        """Return queue statistics."""
        with self._lock:
            return {
                "total_put": self._total_put,
                "total_get": self._total_get,
                "max_size_reached": self._max_size_reached,
                "overflow_count": self._overflow_count,
                "current_size": self._queue.qsize(),
                "maxsize": self._maxsize,
            }


class MockPipelineWorker:
    """
    Mock pipeline worker that simulates DetectionManager's processing loop.

    - Producer thread: reads frames and enqueues jobs
    - Consumer thread: processes jobs (with optional delay)
    """

    def __init__(
        self,
        capture: HighRateVideoCapture,
        job_queue: StressTestQueue,
        processing_delay: float = 0.0,
    ):
        self.capture = capture
        self.job_queue = job_queue
        self.processing_delay = processing_delay

        self._running = False
        self._producer_thread: threading.Thread | None = None
        self._consumer_thread: threading.Thread | None = None

        self._frames_captured = 0
        self._frames_processed = 0
        self._dropped_frames = 0
        self._exceptions: list = []

        self._lock = threading.Lock()

    def start(self):
        """Start producer and consumer threads."""
        self._running = True

        self._producer_thread = threading.Thread(
            target=self._producer_loop,
            name="StressTest-Producer",
            daemon=True,
        )
        self._consumer_thread = threading.Thread(
            target=self._consumer_loop,
            name="StressTest-Consumer",
            daemon=True,
        )

        self._producer_thread.start()
        self._consumer_thread.start()

    def stop(self, timeout: float = 5.0):
        """Stop all threads with timeout."""
        self._running = False

        if self._producer_thread:
            self._producer_thread.join(timeout=timeout)
        if self._consumer_thread:
            self._consumer_thread.join(timeout=timeout)

    def is_alive(self) -> bool:
        """Check if any thread is still running."""
        producer_alive = self._producer_thread and self._producer_thread.is_alive()
        consumer_alive = self._consumer_thread and self._consumer_thread.is_alive()
        return producer_alive or consumer_alive

    def _producer_loop(self):
        """Read frames and enqueue jobs."""
        try:
            while self._running and self.capture.isOpened():
                ret, frame = self.capture.read()
                if not ret:
                    break

                job = MockFrame(
                    data=frame,
                    timestamp=time.time(),
                    frame_id=self.capture.get_frame_count(),
                )

                try:
                    # Non-blocking put with drop on full (backpressure)
                    self.job_queue.put_nowait(job)
                    with self._lock:
                        self._frames_captured += 1
                except queue.Full:
                    with self._lock:
                        self._dropped_frames += 1
        except Exception as e:
            with self._lock:
                self._exceptions.append(("producer", e))

    def _consumer_loop(self):
        """Process jobs from queue."""
        try:
            while self._running or not self.job_queue.empty():
                try:
                    job = self.job_queue.get(timeout=0.1)

                    # Simulate processing with optional delay
                    if self.processing_delay > 0:
                        time.sleep(self.processing_delay)

                    with self._lock:
                        self._frames_processed += 1
                except queue.Empty:
                    if not self._running:
                        break
        except Exception as e:
            with self._lock:
                self._exceptions.append(("consumer", e))

    def get_stats(self) -> dict:
        """Return worker statistics."""
        with self._lock:
            return {
                "frames_captured": self._frames_captured,
                "frames_processed": self._frames_processed,
                "dropped_frames": self._dropped_frames,
                "exceptions": list(self._exceptions),
                "queue_stats": self.job_queue.get_stats(),
            }


import pytest


@pytest.mark.skip(
    reason="Hangs on macOS â€“ tests mock infrastructure, not real app code"
)
class TestThreadingStress:
    """Threading and queue stress tests."""

    def test_high_framerate_no_deadlock(self):
        """
        Test that high frame rate processing doesn't cause deadlocks.

        Generates 100 frames quickly, verifies all are processed or properly
        dropped without permanent blocking.
        """
        capture = HighRateVideoCapture(max_frames=100)  # Reduced for faster test
        job_queue = StressTestQueue(maxsize=10)
        worker = MockPipelineWorker(capture, job_queue, processing_delay=0.0)

        start_time = time.time()
        worker.start()

        # Wait for producer to finish (generous timeout)
        max_wait = 60.0
        while worker.is_alive() and (time.time() - start_time) < max_wait:
            time.sleep(0.1)

        worker.stop(timeout=5.0)
        elapsed = time.time() - start_time

        stats = worker.get_stats()

        # Key assertion: threads stopped (no deadlock)
        assert not worker.is_alive(), "Threads should be stopped (possible deadlock)"

        # Verify no exceptions during processing
        assert len(stats["exceptions"]) == 0, (
            f"Exceptions occurred: {stats['exceptions']}"
        )

        # Verify frames were processed or dropped (not stuck)
        total_handled = stats["frames_captured"] + stats["dropped_frames"]
        assert total_handled == 100, f"Expected 100 frames handled, got {total_handled}"

    def test_backpressure_drops_frames(self):
        """
        Test that backpressure correctly drops frames when queue is full.

        Uses slow processing to ensure queue fills up.
        """
        capture = HighRateVideoCapture(max_frames=100)
        job_queue = StressTestQueue(maxsize=5)
        # Slow processing to cause backpressure
        worker = MockPipelineWorker(capture, job_queue, processing_delay=0.01)

        worker.start()

        # Wait for completion
        time.sleep(2.0)
        worker.stop(timeout=2.0)

        stats = worker.get_stats()
        queue_stats = stats["queue_stats"]

        # Verify backpressure occurred (frames were dropped)
        assert stats["dropped_frames"] > 0, (
            "Expected some frames to be dropped due to backpressure"
        )

        # Verify queue never exceeded maxsize
        assert queue_stats["max_size_reached"] <= 5, (
            f"Queue exceeded maxsize: {queue_stats['max_size_reached']}"
        )

        # Verify overflow was tracked
        assert queue_stats["overflow_count"] == stats["dropped_frames"]

    def test_clean_shutdown_within_timeout(self):
        """
        Test that stop() terminates all threads within specified timeout.
        """
        capture = HighRateVideoCapture(max_frames=10000)  # Long running
        job_queue = StressTestQueue(maxsize=10)
        worker = MockPipelineWorker(capture, job_queue, processing_delay=0.001)

        worker.start()

        # Let it run briefly
        time.sleep(0.5)

        # Stop should complete within timeout
        start_stop = time.time()
        worker.stop(timeout=2.0)
        stop_duration = time.time() - start_stop

        assert stop_duration < 2.5, f"Stop took {stop_duration:.2f}s, expected <2.5s"
        assert not worker.is_alive(), "Threads should be stopped after stop()"

    def test_empty_queue_no_block(self):
        """
        Test that consumer doesn't block forever on empty queue during shutdown.
        """
        capture = HighRateVideoCapture(max_frames=0)  # No frames
        job_queue = StressTestQueue(maxsize=10)
        worker = MockPipelineWorker(capture, job_queue)

        worker.start()
        time.sleep(0.1)

        # Should stop quickly even with nothing to process
        start_stop = time.time()
        worker.stop(timeout=1.0)
        stop_duration = time.time() - start_stop

        assert stop_duration < 1.5, f"Stop took {stop_duration:.2f}s on empty queue"
        assert not worker.is_alive()

    def test_multiple_start_stop_cycles(self):
        """
        Test that worker can be started and stopped multiple times.

        Verifies no resource leaks or state corruption.
        """
        for cycle in range(3):
            capture = HighRateVideoCapture(max_frames=50)
            job_queue = StressTestQueue(maxsize=10)
            worker = MockPipelineWorker(capture, job_queue)

            worker.start()
            time.sleep(0.3)
            worker.stop(timeout=1.0)

            stats = worker.get_stats()

            assert not worker.is_alive(), f"Cycle {cycle}: threads should be stopped"
            assert len(stats["exceptions"]) == 0, f"Cycle {cycle}: had exceptions"

    def test_queue_stats_accuracy(self):
        """
        Test that queue statistics are accurately tracked.
        """
        job_queue = StressTestQueue(maxsize=5)

        # Put some items
        for i in range(5):
            job_queue.put(f"item_{i}")

        stats = job_queue.get_stats()
        assert stats["total_put"] == 5
        assert stats["current_size"] == 5
        assert stats["max_size_reached"] == 5

        # Get some items
        for _i in range(3):
            job_queue.get()

        stats = job_queue.get_stats()
        assert stats["total_get"] == 3
        assert stats["current_size"] == 2

        # Try overflow
        for i in range(10):
            try:
                job_queue.put(f"overflow_{i}", block=False)
            except queue.Full:
                pass

        stats = job_queue.get_stats()
        assert stats["overflow_count"] > 0

    def test_concurrent_put_get(self):
        """
        Test concurrent put and get operations don't corrupt queue state.
        """
        job_queue = StressTestQueue(maxsize=100)

        put_count = [0]
        get_count = [0]
        errors = []

        def producer():
            try:
                for i in range(500):
                    try:
                        job_queue.put(f"item_{i}", timeout=0.01)
                        put_count[0] += 1
                    except queue.Full:
                        pass
            except Exception as e:
                errors.append(("producer", e))

        def consumer():
            try:
                while get_count[0] < 400 or not job_queue.empty():
                    try:
                        job_queue.get(timeout=0.01)
                        get_count[0] += 1
                    except queue.Empty:
                        time.sleep(0.001)
            except Exception as e:
                errors.append(("consumer", e))

        # Start concurrent threads
        threads = [
            threading.Thread(target=producer),
            threading.Thread(target=producer),
            threading.Thread(target=consumer),
            threading.Thread(target=consumer),
        ]

        for t in threads:
            t.start()

        for t in threads:
            t.join(timeout=5.0)

        # Verify no errors
        assert len(errors) == 0, f"Errors during concurrent access: {errors}"

        # Verify stats are consistent
        stats = job_queue.get_stats()
        assert stats["total_get"] <= stats["total_put"]

    def test_stress_200_cycles(self):
        """
        Stress test: Process 200 frames rapidly.

        Verifies system stability under sustained load.
        """
        capture = HighRateVideoCapture(max_frames=200)  # Reduced for reliability
        job_queue = StressTestQueue(maxsize=20)
        worker = MockPipelineWorker(capture, job_queue, processing_delay=0.0)

        start_time = time.time()
        worker.start()

        # Wait for completion
        max_wait = 120.0
        while worker.is_alive() and (time.time() - start_time) < max_wait:
            time.sleep(0.1)

        worker.stop(timeout=5.0)
        elapsed = time.time() - start_time

        stats = worker.get_stats()

        # Key assertion: clean completion
        assert not worker.is_alive(), "Threads should be stopped"

        # No exceptions
        assert len(stats["exceptions"]) == 0, f"Exceptions: {stats['exceptions']}"

        # All frames accounted for
        total = stats["frames_captured"] + stats["dropped_frames"]
        assert total == 200, f"Expected 200 frames, got {total}"
